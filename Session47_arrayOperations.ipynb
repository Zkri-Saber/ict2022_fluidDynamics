{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greenty5/ict2022_fluidDynamics/blob/main/Session47_arrayOperations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBGCsfys8VUw"
      },
      "source": [
        "ICT Summer School 2022\n",
        "Fluid Dynamics with Python\n",
        "=====\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MFF91_18VUx"
      },
      "source": [
        "Session 4.7 Array Operations with NumPy\n",
        "----------------\n",
        "\n",
        "For more computationally intensive programs, the use of built-in Numpy functions can provide an  increase in execution speed many-times over.  As a simple example, consider the following equation:\n",
        "\n",
        "$$u^{n+1}_i = u^n_i-u^n_{i-1}$$\n",
        "\n",
        "Now, given a vector $u^n = [0, 1, 2, 3, 4, 5]\\ \\ $   we can calculate the values of $u^{n+1}$ by iterating over the values of $u^n$ with a for loop.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-yB2HcL8VUx"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2Axb7HO8VUy",
        "outputId": "5c19320a-9daf-492c-9d39-63f19cd4132a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "u = np.array((0, 1, 2, 3, 4, 5))\n",
        "\n",
        "for i in range(1, len(u)):\n",
        "    print(u[i] - u[i-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_CrukxS8VUy"
      },
      "source": [
        "This is the expected result and the execution time was nearly instantaneous.  If we perform the same operation as an array operation, then rather than calculate $u^n_i-u^n_{i-1}\\ $ 5 separate times, we can slice the $u$ array and calculate each operation with one command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL1-NuZd8VUz",
        "outputId": "ac89d304-77bb-4bfe-d86e-5a436ed0139d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "u[1:] - u[0:-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYXJf-I08VUz"
      },
      "source": [
        "What this command says is subtract the 0th, 1st, 2nd, 3rd, 4th and 5th elements of $u$ from the 1st, 2nd, 3rd, 4th, 5th and 6th elements of $u$.  \n",
        "\n",
        "### Speed Increases\n",
        "\n",
        "For a 6 element array, the benefits of array operations are pretty slim.  There will be no appreciable difference in execution time because there are so few operations taking place.  But if we revisit 2D linear convection, we can see some substantial speed increases.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2704zHD8VUz"
      },
      "outputs": [],
      "source": [
        "nx = 81\n",
        "ny = 81\n",
        "nt = 100\n",
        "c = 1\n",
        "dx = 2 / (nx - 1)\n",
        "dy = 2 / (ny - 1)\n",
        "sigma = .2\n",
        "dt = sigma * dx\n",
        "\n",
        "x = np.linspace(0, 2, nx)\n",
        "y = np.linspace(0, 2, ny)\n",
        "\n",
        "u = np.ones((ny, nx)) ##create a 1xn vector of 1's\n",
        "un = np.ones((ny, nx)) \n",
        "\n",
        "###Assign initial conditions\n",
        "\n",
        "u[int(.5 / dy): int(1 / dy + 1), int(.5 / dx):int(1 / dx + 1)] = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW_I19XQ8VUz"
      },
      "source": [
        "With our initial conditions all set up, let's first try running our original nested loop code, making use of the iPython \"magic\" function `%%timeit`, which will help us evaluate the performance of our code. \n",
        "\n",
        "**Note**: The `%%timeit` magic function will run the code several times and then give an average execution time as a result.  If you have any figures being plotted within a cell where you run `%%timeit`, it will plot those figures repeatedly which can be a bit messy. \n",
        "\n",
        "The execution times below will vary from machine to machine.  Don't expect your times to match these times, but you _should_ expect to see the same general trend in decreasing execution time as we switch to array operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg2LDzLh8VU0",
        "outputId": "f0fc9a63-f83a-4d1b-e6f0-6fa1546c38f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 2.4 s per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "u = np.ones((ny, nx))\n",
        "u[int(.5 / dy): int(1 / dy + 1), int(.5 / dx):int(1 / dx + 1)] = 2\n",
        "\n",
        "for n in range(nt + 1): ##loop across number of time steps\n",
        "    un = u.copy()\n",
        "    row, col = u.shape\n",
        "    for j in range(1, row):\n",
        "        for i in range(1, col):\n",
        "            u[j, i] = (un[j, i] - (c * dt / dx * \n",
        "                                  (un[j, i] - un[j, i - 1])) - \n",
        "                                  (c * dt / dy * \n",
        "                                   (un[j, i] - un[j - 1, i])))\n",
        "            u[0, :] = 1\n",
        "            u[-1, :] = 1\n",
        "            u[:, 0] = 1\n",
        "            u[:, -1] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pukx-KXD8VU0"
      },
      "source": [
        "With the \"raw\" Python code above, the mean execution time achieved was about 2.4 seconds (on Google Colaboratory).  Keep in mind that with these three nested loops, that the statements inside the **j** loop are being evaluated more than 650,000 times.   Let's compare that with the performance of the same code implemented with <font color='orange'>array operations</font>:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb3FIZ0r8VU0",
        "outputId": "c9e0d12d-30c8-44e5-a0a5-eed909aafcc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 4.56 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "u = np.ones((ny, nx))\n",
        "u[int(.5 / dy): int(1 / dy + 1), int(.5 / dx):int(1 / dx + 1)] = 2\n",
        "\n",
        "for n in range(nt + 1): ##loop across number of time steps\n",
        "  un = u.copy()\n",
        "\n",
        "  # write your own code here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qA14ONU8VU0"
      },
      "source": [
        "As you can see, the speed increase is substantial.  The same calculation goes from 2.4 seconds to 4.56 milliseconds.  2.4 seconds isn't a huge amount of time to wait, but these speed gains will increase exponentially with the size and complexity of the problem being evaluated.  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "eDDSB-YQWz3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Job well done, everyone ðŸ˜€"
      ],
      "metadata": {
        "id": "qFUpV4PGW1_V"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Session47_arrayOperations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}